{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Segmentation\n",
    "\n",
    "Using the master dataset's onset times, cut each continuous audio recording into individual \"boxemes\" (isolated vocal percussion sounds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(master_df, output_dir, segment_duration=0.5):\n",
    "    \"\"\"\n",
    "    Segments audio files and saves them to disk.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    segment_info = []\n",
    "    \n",
    "    # Group by wav_file_path\n",
    "    for wav_path, group in tqdm(master_df.groupby('wav_file_path')):\n",
    "        print(f\"\\nProcessing {wav_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Use soundfile instead of librosa.load\n",
    "            y, sr = sf.read(wav_path)\n",
    "            \n",
    "            # Process each onset in this file\n",
    "            for idx, row in group.iterrows():\n",
    "                start_sample = int(row['onset_time'] * sr)\n",
    "                end_sample = start_sample + int(segment_duration * sr)\n",
    "                \n",
    "                # Handle edge cases\n",
    "                if start_sample < 0:\n",
    "                    start_sample = 0\n",
    "                if end_sample > len(y):\n",
    "                    end_sample = len(y)\n",
    "                \n",
    "                if end_sample > start_sample:\n",
    "                    segment = y[start_sample:end_sample]\n",
    "                    \n",
    "                    # Pad if needed\n",
    "                    if len(segment) < int(segment_duration * sr):\n",
    "                        segment = np.pad(segment, \n",
    "                                      (0, int(segment_duration * sr) - len(segment)),\n",
    "                                      mode='constant')\n",
    "                    \n",
    "                    segment_filename = (f\"{row['dataset']}_{row['participant_id']}_\"\n",
    "                                     f\"{row['instrument_label']}_{idx:04d}.wav\")\n",
    "                    \n",
    "                    segment_path = output_dir / segment_filename\n",
    "                    sf.write(str(segment_path), segment, sr)\n",
    "                    \n",
    "                    segment_info.append({\n",
    "                        'segment_path': str(segment_path),\n",
    "                        'instrument_label': row['instrument_label'],\n",
    "                        'participant_id': row['participant_id'],\n",
    "                        'dataset': row['dataset'],\n",
    "                        'original_wav': wav_path,\n",
    "                        'onset_time': row['onset_time'],\n",
    "                        'onset_phoneme': row['onset_phoneme'],\n",
    "                        'coda_phoneme': row['coda_phoneme']\n",
    "                    })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {wav_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    segment_df = pd.DataFrame(segment_info)\n",
    "    os.makedirs('../segment_info', exist_ok=True)\n",
    "    segment_df.to_csv('../segment_info/segment_info.csv', index=False)\n",
    "    \n",
    "    return segment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting audio segmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 10/180 [00:00<00:01, 98.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_1/P1_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_1/P1_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_1/P1_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_1/P1_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_1/P1_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_10/P10_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_10/P10_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_10/P10_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_10/P10_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_10/P10_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_11/P11_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_11/P11_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_11/P11_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_11/P11_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_11/P11_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_12/P12_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_12/P12_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_12/P12_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_12/P12_Kick_Personal.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 31/180 [00:00<00:01, 99.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_12/P12_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_13/P13_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_13/P13_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_13/P13_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_13/P13_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_13/P13_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_14/P14_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_14/P14_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_14/P14_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_14/P14_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_14/P14_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_15/P15_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_15/P15_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_15/P15_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_15/P15_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_15/P15_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_16/P16_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_16/P16_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_16/P16_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_16/P16_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_16/P16_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_17/P17_HHclosed_Personal.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 52/180 [00:00<00:01, 88.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_17/P17_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_17/P17_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_17/P17_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_17/P17_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_18/P18_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_18/P18_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_18/P18_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_18/P18_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_18/P18_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_19/P19_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_19/P19_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_19/P19_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_19/P19_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_19/P19_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_2/P2_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_2/P2_HHopened_Personal.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 70/180 [00:00<00:01, 84.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_2/P2_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_2/P2_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_2/P2_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_20/P20_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_20/P20_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_20/P20_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_20/P20_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_20/P20_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_21/P21_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_21/P21_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_21/P21_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_21/P21_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_21/P21_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_22/P22_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_22/P22_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_22/P22_Improvisation_Personal.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 88/180 [00:01<00:01, 77.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_22/P22_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_22/P22_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_23/P23_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_23/P23_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_23/P23_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_23/P23_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_23/P23_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_24/P24_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_24/P24_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_24/P24_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_24/P24_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_24/P24_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_25/P25_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_25/P25_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_25/P25_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_25/P25_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_25/P25_Snare_Personal.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 108/180 [00:01<00:00, 84.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_26/P26_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_26/P26_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_26/P26_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_26/P26_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_26/P26_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_27/P27_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_27/P27_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_27/P27_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_27/P27_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_27/P27_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_28/P28_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_28/P28_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_28/P28_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_28/P28_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_28/P28_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_3/P3_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_3/P3_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_3/P3_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_3/P3_Kick_Personal.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 130/180 [00:01<00:00, 96.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_3/P3_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_4/P4_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_4/P4_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_4/P4_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_4/P4_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_4/P4_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_5/P5_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_5/P5_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_5/P5_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_5/P5_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_5/P5_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_6/P6_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_6/P6_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_6/P6_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_6/P6_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_6/P6_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_7/P7_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_7/P7_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_7/P7_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_7/P7_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_7/P7_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_8/P8_HHclosed_Personal.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 142/180 [00:01<00:00, 101.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_8/P8_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_8/P8_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_8/P8_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_8/P8_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_9/P9_HHclosed_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_9/P9_HHopened_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_9/P9_Improvisation_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_9/P9_Kick_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/AVP_Dataset/Personal/Participant_9/P9_Snare_Personal.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/AFRP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/AZiP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/BeaP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/BicP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/CatP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/CavP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/CraP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/IsaP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/JOlP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/JSiP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/JoSP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/MCoP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/MafP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/MarP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/NorP3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:01<00:00, 96.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/RicP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/RobP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/SofP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/ZgaP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Frase/ZizP3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/AFRI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/AZiI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/BeaI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/BicI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/CatI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/CavI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/CraI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/IsaI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/JOlI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/JSiI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/JSoI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/MCoI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/MafI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/MarI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/NorI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/RicI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/RobI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/SofI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/ZgaI3.wav\n",
      "\n",
      "Processing ../../AVP-LVT_Dataset/LVT_Dataset/Improviso/ZizI3.wav\n",
      "\n",
      "Segmentation Summary:\n",
      "Total segments extracted: 5714\n",
      "\n",
      "Instrument distribution:\n",
      "instrument_label\n",
      "kd     1776\n",
      "hhc    1498\n",
      "sd     1431\n",
      "hho    1009\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "AVP    4873\n",
      "LVT     841\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "master_df = pd.read_csv('../data/master_dataset.csv')\n",
    "    \n",
    "# Segment all audio files\n",
    "print(\"Starting audio segmentation...\")\n",
    "segment_df = segment_audio(master_df, output_dir='../segments')\n",
    "    \n",
    "# Print summary\n",
    "print(\"\\nSegmentation Summary:\")\n",
    "print(f\"Total segments extracted: {len(segment_df)}\")\n",
    "print(\"\\nInstrument distribution:\")\n",
    "print(segment_df['instrument_label'].value_counts())\n",
    "print(\"\\nDataset distribution:\")\n",
    "print(segment_df['dataset'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beatbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
