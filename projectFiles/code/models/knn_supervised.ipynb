{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def load_features_and_labels(features_path, labels_path, segment_info_path):\n",
    "    \"\"\"\n",
    "    Load features and labels from specified paths.\n",
    "    \n",
    "    Args:\n",
    "        features_path (str): Path to the .npy file containing features\n",
    "        labels_path (str): Path to the .npy file containing labels\n",
    "        segment_info_path (str): Path to the CSV file containing segment information\n",
    "    \n",
    "    Returns:\n",
    "        X (np.array): Feature matrix\n",
    "        y (np.array): Labels\n",
    "        segment_info (pd.DataFrame): DataFrame containing segment information\n",
    "    \"\"\"\n",
    "    # Load features and labels\n",
    "    X = np.load(features_path)\n",
    "    y = np.load(labels_path)\n",
    "    \n",
    "    # Load segment info\n",
    "    segment_info = pd.read_csv(segment_info_path)\n",
    "    \n",
    "    # Verify that the number of samples matches\n",
    "    assert len(X) == len(y) == len(segment_info), \\\n",
    "        \"Mismatch in number of samples between features, labels, and segment info\"\n",
    "    \n",
    "    return X, y, segment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_participant_split(X, y, segment_info, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data ensuring:\n",
    "    1. No augmented versions of test set samples in training set\n",
    "    2. Each participant has samples of each instrument type they recorded in training set\n",
    "    3. Stratification by instrument label\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Feature matrix\n",
    "        y (np.array): Labels\n",
    "        segment_info (pd.DataFrame): DataFrame containing segment information\n",
    "        test_size (float): Proportion of data for testing\n",
    "        random_state (int): Random seed\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, train_indices, test_indices\n",
    "    \"\"\"\n",
    "    # Check if we're dealing with augmented data by looking at segment paths\n",
    "    is_augmented = segment_info['segment_path'].str.contains('_aug\\\\d+\\\\.wav').any()\n",
    "    \n",
    "    if is_augmented:\n",
    "        # For augmented data, extract original segment names\n",
    "        segment_info['original_name'] = segment_info['segment_path'].apply(\n",
    "            lambda x: x.split('_aug')[0] + '.wav' if '_aug' in x else x\n",
    "        )\n",
    "        \n",
    "        # Get unique original segments (non-augmented)\n",
    "        original_segments = segment_info[~segment_info['segment_path'].str.contains('_aug\\\\d+\\\\.wav')]\n",
    "        \n",
    "        # First, ensure at least one sample from each participant in training\n",
    "        train_segments = []\n",
    "        for participant in original_segments['participant_id'].unique():\n",
    "            participant_mask = original_segments['participant_id'] == participant\n",
    "            participant_indices = original_segments[participant_mask].index\n",
    "            \n",
    "            # For each instrument type the participant has\n",
    "            participant_instruments = np.unique(y[participant_indices])\n",
    "            for instrument in participant_instruments:\n",
    "                participant_instrument_segments = original_segments[\n",
    "                    participant_mask & (y[original_segments.index] == instrument)\n",
    "                ]['segment_path'].values\n",
    "                \n",
    "                if len(participant_instrument_segments) > 0:\n",
    "                    train_segments.append(np.random.choice(participant_instrument_segments))\n",
    "        \n",
    "        # Then split remaining original segments\n",
    "        remaining_segments = list(set(original_segments['segment_path']) - set(train_segments))\n",
    "        additional_train, test_segments = train_test_split(\n",
    "            remaining_segments,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y[original_segments[original_segments['segment_path'].isin(remaining_segments)].index]\n",
    "        )\n",
    "        train_segments.extend(additional_train)\n",
    "        \n",
    "        # Get indices for train and test (including augmented versions for train)\n",
    "        train_indices = segment_info[\n",
    "            (segment_info['segment_path'].isin(train_segments)) |\n",
    "            (segment_info['original_name'].isin(train_segments))\n",
    "        ].index\n",
    "        \n",
    "        # For test, only use original (non-augmented) segments\n",
    "        test_indices = segment_info[\n",
    "            segment_info['segment_path'].isin(test_segments)\n",
    "        ].index\n",
    "        \n",
    "    else:\n",
    "        # For non-augmented data, ensure participant representation directly\n",
    "        train_indices = []\n",
    "        \n",
    "        # First, ensure each participant has at least one sample of each instrument they recorded\n",
    "        for participant in segment_info['participant_id'].unique():\n",
    "            participant_mask = segment_info['participant_id'] == participant\n",
    "            participant_indices = segment_info[participant_mask].index\n",
    "            \n",
    "            # For each instrument type the participant has\n",
    "            participant_instruments = np.unique(y[participant_indices])\n",
    "            for instrument in participant_instruments:\n",
    "                participant_instrument_indices = segment_info[\n",
    "                    participant_mask & (y == instrument)\n",
    "                ].index\n",
    "                if len(participant_instrument_indices) > 0:\n",
    "                    train_indices.append(np.random.choice(participant_instrument_indices))\n",
    "        \n",
    "        # Split remaining indices\n",
    "        remaining_indices = list(set(range(len(y))) - set(train_indices))\n",
    "        additional_train, test_indices = train_test_split(\n",
    "            remaining_indices,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y[remaining_indices]\n",
    "        )\n",
    "        train_indices.extend(additional_train)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    train_indices = np.array(train_indices)\n",
    "    test_indices = np.array(test_indices)\n",
    "    \n",
    "    # Verify no overlap between train and test\n",
    "    assert len(set(train_indices) & set(test_indices)) == 0, \\\n",
    "        \"Overlap found between train and test sets\"\n",
    "    \n",
    "    # Print split statistics\n",
    "    print(f\"\\nSplit Statistics:\")\n",
    "    print(f\"Training set size: {len(train_indices)}\")\n",
    "    print(f\"Test set size: {len(test_indices)}\")\n",
    "    print(\"\\nLabel distribution in training set:\")\n",
    "    print(pd.Series(y[train_indices]).value_counts())\n",
    "    print(\"\\nLabel distribution in test set:\")\n",
    "    print(pd.Series(y[test_indices]).value_counts())\n",
    "    print(\"\\nParticipant distribution in training set:\")\n",
    "    print(segment_info.iloc[train_indices]['participant_id'].value_counts().head())\n",
    "    print(\"\\nParticipant distribution in test set:\")\n",
    "    print(segment_info.iloc[test_indices]['participant_id'].value_counts().head())\n",
    "    \n",
    "    return (X[train_indices], X[test_indices], \n",
    "            y[train_indices], y[test_indices],\n",
    "            train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_knn(X_train, X_test, y_train, y_test, cv=5):\n",
    "    \"\"\"\n",
    "    Train KNN model with hyperparameter tuning and evaluate it.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: Training and test data\n",
    "        cv (int): Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "        best_model: Trained model with best parameters\n",
    "        best_params: Best hyperparameters\n",
    "        cv_results: Cross-validation results\n",
    "    \"\"\"\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Encode labels\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    # Store label mapping for later use\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(\"\\nLabel mapping:\", label_mapping)\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "    \n",
    "    # Initialize and train model with GridSearchCV\n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Ensure all classes are present in each fold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    cv_splitter = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        knn, \n",
    "        param_grid, \n",
    "        cv=cv_splitter,\n",
    "        scoring='accuracy', \n",
    "        n_jobs=-1,\n",
    "        error_score=0.0  # Return score of 0 for failed fits\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "    \n",
    "    # Get best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_encoded = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert predictions back to original labels for reporting\n",
    "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nBest parameters:\", best_params)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add label encoder to the results\n",
    "    best_model.label_encoder_ = label_encoder\n",
    "    \n",
    "    return best_model, best_params, grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing mfcc features...\n",
      "\n",
      "Split Statistics:\n",
      "Training set size: 4617\n",
      "Test set size: 1097\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     1434\n",
      "hhc    1212\n",
      "sd     1158\n",
      "hho     813\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     342\n",
      "hhc    286\n",
      "sd     273\n",
      "hho    196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in training set:\n",
      "participant_id\n",
      "P18    239\n",
      "P22    237\n",
      "P25    214\n",
      "P21    196\n",
      "P28    176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in test set:\n",
      "participant_id\n",
      "P18    68\n",
      "P22    56\n",
      "P25    52\n",
      "P28    46\n",
      "P5     36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.82      0.81      0.82       286\n",
      "         hho       0.92      0.91      0.92       196\n",
      "          kd       0.80      0.84      0.82       342\n",
      "          sd       0.86      0.82      0.84       273\n",
      "\n",
      "    accuracy                           0.84      1097\n",
      "   macro avg       0.85      0.84      0.85      1097\n",
      "weighted avg       0.84      0.84      0.84      1097\n",
      "\n",
      "\n",
      "Processing mfcc_env features...\n",
      "\n",
      "Split Statistics:\n",
      "Training set size: 4617\n",
      "Test set size: 1097\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     1434\n",
      "hhc    1212\n",
      "sd     1158\n",
      "hho     813\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     342\n",
      "hhc    286\n",
      "sd     273\n",
      "hho    196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in training set:\n",
      "participant_id\n",
      "P18    239\n",
      "P22    237\n",
      "P25    214\n",
      "P21    196\n",
      "P28    176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in test set:\n",
      "participant_id\n",
      "P18    68\n",
      "P22    56\n",
      "P25    52\n",
      "P28    46\n",
      "P5     36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.90      0.88      0.89       286\n",
      "         hho       0.90      0.92      0.91       196\n",
      "          kd       0.91      0.96      0.93       342\n",
      "          sd       0.96      0.90      0.93       273\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.92      0.91      0.91      1097\n",
      "weighted avg       0.92      0.92      0.92      1097\n",
      "\n",
      "\n",
      "Processing mfcc_extracted features...\n",
      "\n",
      "Split Statistics:\n",
      "Training set size: 4617\n",
      "Test set size: 1097\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     1434\n",
      "hhc    1212\n",
      "sd     1158\n",
      "hho     813\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     342\n",
      "hhc    286\n",
      "sd     273\n",
      "hho    196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in training set:\n",
      "participant_id\n",
      "P18    239\n",
      "P22    237\n",
      "P25    214\n",
      "P21    196\n",
      "P28    176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in test set:\n",
      "participant_id\n",
      "P18    68\n",
      "P22    56\n",
      "P25    52\n",
      "P28    46\n",
      "P5     36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.81      0.85      0.83       286\n",
      "         hho       0.87      0.80      0.84       196\n",
      "          kd       0.88      0.88      0.88       342\n",
      "          sd       0.82      0.82      0.82       273\n",
      "\n",
      "    accuracy                           0.84      1097\n",
      "   macro avg       0.85      0.84      0.84      1097\n",
      "weighted avg       0.84      0.84      0.84      1097\n",
      "\n",
      "\n",
      "Processing mfcc_aug features...\n",
      "\n",
      "Split Statistics:\n",
      "Training set size: 27702\n",
      "Test set size: 1097\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     8514\n",
      "hhc    7254\n",
      "sd     7020\n",
      "hho    4914\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     357\n",
      "hhc    289\n",
      "sd     261\n",
      "hho    190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in training set:\n",
      "participant_id\n",
      "P18    1422\n",
      "P22    1404\n",
      "P25    1302\n",
      "P21    1104\n",
      "P28    1062\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in test set:\n",
      "participant_id\n",
      "P18    70\n",
      "P22    59\n",
      "P25    49\n",
      "P21    48\n",
      "P28    45\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.79      0.84      0.82       289\n",
      "         hho       0.91      0.85      0.88       190\n",
      "          kd       0.82      0.80      0.81       357\n",
      "          sd       0.82      0.82      0.82       261\n",
      "\n",
      "    accuracy                           0.83      1097\n",
      "   macro avg       0.84      0.83      0.83      1097\n",
      "weighted avg       0.83      0.83      0.83      1097\n",
      "\n",
      "\n",
      "Processing mfcc_env_aug features...\n",
      "\n",
      "Split Statistics:\n",
      "Training set size: 27702\n",
      "Test set size: 1097\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     8682\n",
      "hhc    7344\n",
      "sd     6792\n",
      "hho    4884\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     329\n",
      "sd     299\n",
      "hhc    274\n",
      "hho    195\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in training set:\n",
      "participant_id\n",
      "P18    1542\n",
      "P22    1410\n",
      "P25    1254\n",
      "P21    1140\n",
      "P28    1104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in test set:\n",
      "participant_id\n",
      "P22    58\n",
      "P25    57\n",
      "P18    50\n",
      "P24    43\n",
      "P21    42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.87      0.89      0.88       274\n",
      "         hho       0.90      0.89      0.90       195\n",
      "          kd       0.93      0.93      0.93       329\n",
      "          sd       0.93      0.91      0.92       299\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.91      0.91      0.91      1097\n",
      "weighted avg       0.91      0.91      0.91      1097\n",
      "\n",
      "\n",
      "Processing mfcc_extracted_aug features...\n",
      "\n",
      "Split Statistics:\n",
      "Training set size: 27702\n",
      "Test set size: 1097\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     8580\n",
      "hhc    7338\n",
      "sd     6996\n",
      "hho    4788\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     346\n",
      "hhc    275\n",
      "sd     265\n",
      "hho    211\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in training set:\n",
      "participant_id\n",
      "P18    1488\n",
      "P22    1374\n",
      "P25    1272\n",
      "P21    1098\n",
      "P28    1056\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant distribution in test set:\n",
      "participant_id\n",
      "P22    64\n",
      "P18    59\n",
      "P25    54\n",
      "P21    49\n",
      "P28    46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.82      0.79      0.81       275\n",
      "         hho       0.89      0.87      0.88       211\n",
      "          kd       0.87      0.88      0.87       346\n",
      "          sd       0.84      0.87      0.85       265\n",
      "\n",
      "    accuracy                           0.85      1097\n",
      "   macro avg       0.85      0.85      0.85      1097\n",
      "weighted avg       0.85      0.85      0.85      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_sets = [\n",
    "        {\n",
    "            'name': 'mfcc',\n",
    "            'features_path': '../../extracted_features/features/mfcc_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_env',\n",
    "            'features_path': '../../extracted_features/features/mfcc_env_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_env_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_extracted',\n",
    "            'features_path': '../../extracted_features/features/mfcc_extracted_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_extracted_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_aug',\n",
    "            'features_path': '../../extracted_features/features/mfcc_features_aug.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_labels_aug.npy',\n",
    "            'segment_info_path': '../../segment_info/augmented_segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_env_aug',\n",
    "            'features_path': '../../extracted_features/features/mfcc_env_aug_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_env_aug_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/augmented_segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_extracted_aug',\n",
    "            'features_path': '../../extracted_features/features/mfcc_extracted_aug_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_extracted_aug_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/augmented_segment_info.csv'\n",
    "        }\n",
    "]\n",
    "    \n",
    "results = {}\n",
    "    \n",
    "for feature_set in feature_sets:\n",
    "    print(f\"\\nProcessing {feature_set['name']} features...\")\n",
    "        \n",
    "        # Load data\n",
    "    X, y, segment_info = load_features_and_labels(\n",
    "            feature_set['features_path'],\n",
    "            feature_set['labels_path'],\n",
    "            feature_set['segment_info_path']\n",
    "    )\n",
    "        \n",
    "        # Split data\n",
    "    X_train, X_test, y_train, y_test, train_idx, test_idx = stratified_participant_split(X, y, segment_info)\n",
    "        \n",
    "        # Train and evaluate\n",
    "    best_model, best_params, cv_results = train_evaluate_knn(\n",
    "        X_train, X_test, y_train, y_test\n",
    "    )\n",
    "        \n",
    "        # Store results\n",
    "    results[feature_set['name']] = {\n",
    "            'best_model': best_model,\n",
    "            'best_params': best_params,\n",
    "            'cv_results': cv_results,\n",
    "            'test_indices': test_idx\n",
    "    }\n",
    "        \n",
    "        # Save confusion matrix plot\n",
    "    plt.savefig(f\"../../visualization/confusion_matrix_{feature_set['name']}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing mfcc features...\n",
      "\n",
      "Participant-Independent Split Statistics:\n",
      "Training participants: ['AFRI', 'AZiI', 'AZiP', 'BeaI', 'BeaP', 'BicI', 'BicP', 'CatI', 'CatP', 'CavI', 'CavP', 'CraI', 'CraP', 'IsaI', 'IsaP', 'JOlI', 'JOlP', 'JSiI', 'JSiP', 'JoSP', 'MCoI', 'MCoP', 'MafI', 'MafP', 'NorI', 'NorP', 'P1', 'P10', 'P11', 'P12', 'P15', 'P16', 'P17', 'P19', 'P2', 'P21', 'P22', 'P23', 'P25', 'P26', 'P27', 'P28', 'P3', 'P4', 'P5', 'P6', 'P8', 'P9', 'RicI', 'RicP', 'RobI', 'RobP', 'SofP', 'ZgaI', 'ZizI']\n",
      "Test participants: ['AFRP', 'JSoI', 'MarI', 'MarP', 'P13', 'P14', 'P18', 'P20', 'P24', 'P7', 'SofI', 'ZgaP', 'ZizP']\n",
      "\n",
      "Training set size: 4557\n",
      "Test set size: 1157\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     1439\n",
      "hhc    1169\n",
      "sd     1146\n",
      "hho     803\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     337\n",
      "hhc    329\n",
      "sd     285\n",
      "hho    206\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.45      0.35      0.39       329\n",
      "         hho       0.39      0.28      0.33       206\n",
      "          kd       0.66      0.81      0.72       337\n",
      "          sd       0.38      0.46      0.42       285\n",
      "\n",
      "    accuracy                           0.50      1157\n",
      "   macro avg       0.47      0.47      0.47      1157\n",
      "weighted avg       0.48      0.50      0.48      1157\n",
      "\n",
      "\n",
      "Processing mfcc_env features...\n",
      "\n",
      "Participant-Independent Split Statistics:\n",
      "Training participants: ['AFRI', 'AZiI', 'AZiP', 'BeaI', 'BeaP', 'BicI', 'BicP', 'CatI', 'CatP', 'CavI', 'CavP', 'CraI', 'CraP', 'IsaI', 'IsaP', 'JOlI', 'JOlP', 'JSiI', 'JSiP', 'JoSP', 'MCoI', 'MCoP', 'MafI', 'MafP', 'NorI', 'NorP', 'P1', 'P10', 'P11', 'P12', 'P15', 'P16', 'P17', 'P19', 'P2', 'P21', 'P22', 'P23', 'P25', 'P26', 'P27', 'P28', 'P3', 'P4', 'P5', 'P6', 'P8', 'P9', 'RicI', 'RicP', 'RobI', 'RobP', 'SofP', 'ZgaI', 'ZizI']\n",
      "Test participants: ['AFRP', 'JSoI', 'MarI', 'MarP', 'P13', 'P14', 'P18', 'P20', 'P24', 'P7', 'SofI', 'ZgaP', 'ZizP']\n",
      "\n",
      "Training set size: 4557\n",
      "Test set size: 1157\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     1439\n",
      "hhc    1169\n",
      "sd     1146\n",
      "hho     803\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     337\n",
      "hhc    329\n",
      "sd     285\n",
      "hho    206\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.47      0.53      0.50       329\n",
      "         hho       0.26      0.18      0.21       206\n",
      "          kd       0.78      0.88      0.82       337\n",
      "          sd       0.50      0.46      0.48       285\n",
      "\n",
      "    accuracy                           0.55      1157\n",
      "   macro avg       0.50      0.51      0.50      1157\n",
      "weighted avg       0.53      0.55      0.54      1157\n",
      "\n",
      "\n",
      "Processing mfcc_extracted features...\n",
      "\n",
      "Participant-Independent Split Statistics:\n",
      "Training participants: ['AFRI', 'AZiI', 'AZiP', 'BeaI', 'BeaP', 'BicI', 'BicP', 'CatI', 'CatP', 'CavI', 'CavP', 'CraI', 'CraP', 'IsaI', 'IsaP', 'JOlI', 'JOlP', 'JSiI', 'JSiP', 'JoSP', 'MCoI', 'MCoP', 'MafI', 'MafP', 'NorI', 'NorP', 'P1', 'P10', 'P11', 'P12', 'P15', 'P16', 'P17', 'P19', 'P2', 'P21', 'P22', 'P23', 'P25', 'P26', 'P27', 'P28', 'P3', 'P4', 'P5', 'P6', 'P8', 'P9', 'RicI', 'RicP', 'RobI', 'RobP', 'SofP', 'ZgaI', 'ZizI']\n",
      "Test participants: ['AFRP', 'JSoI', 'MarI', 'MarP', 'P13', 'P14', 'P18', 'P20', 'P24', 'P7', 'SofI', 'ZgaP', 'ZizP']\n",
      "\n",
      "Training set size: 4557\n",
      "Test set size: 1157\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     1439\n",
      "hhc    1169\n",
      "sd     1146\n",
      "hho     803\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     337\n",
      "hhc    329\n",
      "sd     285\n",
      "hho    206\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.53      0.52      0.52       329\n",
      "         hho       0.35      0.27      0.30       206\n",
      "          kd       0.73      0.80      0.77       337\n",
      "          sd       0.53      0.57      0.55       285\n",
      "\n",
      "    accuracy                           0.57      1157\n",
      "   macro avg       0.54      0.54      0.54      1157\n",
      "weighted avg       0.56      0.57      0.56      1157\n",
      "\n",
      "\n",
      "Processing mfcc_aug features...\n",
      "\n",
      "Participant-Independent Split Statistics:\n",
      "Training participants: ['AFRI', 'AZiI', 'AZiP', 'BeaI', 'BeaP', 'BicI', 'BicP', 'CatI', 'CatP', 'CavI', 'CavP', 'CraI', 'CraP', 'IsaI', 'IsaP', 'JOlI', 'JOlP', 'JSiI', 'JSiP', 'JoSP', 'MCoI', 'MCoP', 'MafI', 'MafP', 'NorI', 'NorP', 'P1', 'P10', 'P11', 'P12', 'P15', 'P16', 'P17', 'P19', 'P2', 'P21', 'P22', 'P23', 'P25', 'P26', 'P27', 'P28', 'P3', 'P4', 'P5', 'P6', 'P8', 'P9', 'RicI', 'RicP', 'RobI', 'RobP', 'SofP', 'ZgaI', 'ZizI']\n",
      "Test participants: ['AFRP', 'JSoI', 'MarI', 'MarP', 'P13', 'P14', 'P18', 'P20', 'P24', 'P7', 'SofI', 'ZgaP', 'ZizP']\n",
      "\n",
      "Training set size: 27342\n",
      "Test set size: 1157\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     8634\n",
      "hhc    7014\n",
      "sd     6876\n",
      "hho    4818\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     337\n",
      "hhc    329\n",
      "sd     285\n",
      "hho    206\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.44      0.33      0.37       329\n",
      "         hho       0.47      0.34      0.40       206\n",
      "          kd       0.64      0.80      0.71       337\n",
      "          sd       0.43      0.51      0.47       285\n",
      "\n",
      "    accuracy                           0.51      1157\n",
      "   macro avg       0.49      0.50      0.49      1157\n",
      "weighted avg       0.50      0.51      0.50      1157\n",
      "\n",
      "\n",
      "Processing mfcc_env_aug features...\n",
      "\n",
      "Participant-Independent Split Statistics:\n",
      "Training participants: ['AFRI', 'AZiI', 'AZiP', 'BeaI', 'BeaP', 'BicI', 'BicP', 'CatI', 'CatP', 'CavI', 'CavP', 'CraI', 'CraP', 'IsaI', 'IsaP', 'JOlI', 'JOlP', 'JSiI', 'JSiP', 'JoSP', 'MCoI', 'MCoP', 'MafI', 'MafP', 'NorI', 'NorP', 'P1', 'P10', 'P11', 'P12', 'P15', 'P16', 'P17', 'P19', 'P2', 'P21', 'P22', 'P23', 'P25', 'P26', 'P27', 'P28', 'P3', 'P4', 'P5', 'P6', 'P8', 'P9', 'RicI', 'RicP', 'RobI', 'RobP', 'SofP', 'ZgaI', 'ZizI']\n",
      "Test participants: ['AFRP', 'JSoI', 'MarI', 'MarP', 'P13', 'P14', 'P18', 'P20', 'P24', 'P7', 'SofI', 'ZgaP', 'ZizP']\n",
      "\n",
      "Training set size: 27342\n",
      "Test set size: 1157\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     8634\n",
      "hhc    7014\n",
      "sd     6876\n",
      "hho    4818\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     337\n",
      "hhc    329\n",
      "sd     285\n",
      "hho    206\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.47      0.53      0.50       329\n",
      "         hho       0.28      0.17      0.21       206\n",
      "          kd       0.77      0.87      0.81       337\n",
      "          sd       0.48      0.47      0.48       285\n",
      "\n",
      "    accuracy                           0.55      1157\n",
      "   macro avg       0.50      0.51      0.50      1157\n",
      "weighted avg       0.53      0.55      0.53      1157\n",
      "\n",
      "\n",
      "Processing mfcc_extracted_aug features...\n",
      "\n",
      "Participant-Independent Split Statistics:\n",
      "Training participants: ['AFRI', 'AZiI', 'AZiP', 'BeaI', 'BeaP', 'BicI', 'BicP', 'CatI', 'CatP', 'CavI', 'CavP', 'CraI', 'CraP', 'IsaI', 'IsaP', 'JOlI', 'JOlP', 'JSiI', 'JSiP', 'JoSP', 'MCoI', 'MCoP', 'MafI', 'MafP', 'NorI', 'NorP', 'P1', 'P10', 'P11', 'P12', 'P15', 'P16', 'P17', 'P19', 'P2', 'P21', 'P22', 'P23', 'P25', 'P26', 'P27', 'P28', 'P3', 'P4', 'P5', 'P6', 'P8', 'P9', 'RicI', 'RicP', 'RobI', 'RobP', 'SofP', 'ZgaI', 'ZizI']\n",
      "Test participants: ['AFRP', 'JSoI', 'MarI', 'MarP', 'P13', 'P14', 'P18', 'P20', 'P24', 'P7', 'SofI', 'ZgaP', 'ZizP']\n",
      "\n",
      "Training set size: 27342\n",
      "Test set size: 1157\n",
      "\n",
      "Label distribution in training set:\n",
      "kd     8634\n",
      "hhc    7014\n",
      "sd     6876\n",
      "hho    4818\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in test set:\n",
      "kd     337\n",
      "hhc    329\n",
      "sd     285\n",
      "hho    206\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping: {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
      "\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hhc       0.46      0.50      0.48       329\n",
      "         hho       0.35      0.25      0.29       206\n",
      "          kd       0.75      0.79      0.77       337\n",
      "          sd       0.49      0.51      0.50       285\n",
      "\n",
      "    accuracy                           0.54      1157\n",
      "   macro avg       0.51      0.51      0.51      1157\n",
      "weighted avg       0.53      0.54      0.54      1157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def load_features_and_labels(features_path, labels_path, segment_info_path):\n",
    "    \"\"\"\n",
    "    Load features and labels from specified paths.\n",
    "    \n",
    "    Args:\n",
    "        features_path (str): Path to the .npy file containing features\n",
    "        labels_path (str): Path to the .npy file containing labels\n",
    "        segment_info_path (str): Path to the CSV file containing segment information\n",
    "    \n",
    "    Returns:\n",
    "        X (np.array): Feature matrix\n",
    "        y (np.array): Labels\n",
    "        segment_info (pd.DataFrame): DataFrame containing segment information\n",
    "    \"\"\"\n",
    "    # Load features and labels\n",
    "    X = np.load(features_path)\n",
    "    y = np.load(labels_path)\n",
    "    \n",
    "    # Load segment info\n",
    "    segment_info = pd.read_csv(segment_info_path)\n",
    "    \n",
    "    # Verify that the number of samples matches\n",
    "    assert len(X) == len(y) == len(segment_info), \\\n",
    "        \"Mismatch in number of samples between features, labels, and segment info\"\n",
    "    \n",
    "    return X, y, segment_info\n",
    "\n",
    "def participant_independent_split(X, y, segment_info, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data ensuring complete participant independence between train and test sets.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Feature matrix\n",
    "        y (np.array): Labels\n",
    "        segment_info (pd.DataFrame): DataFrame containing segment information\n",
    "        test_size (float): Proportion of participants to use for testing\n",
    "        random_state (int): Random seed\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, train_indices, test_indices\n",
    "    \"\"\"\n",
    "    # Get unique participants\n",
    "    participants = segment_info['participant_id'].unique()\n",
    "    \n",
    "    # Split participants into train and test\n",
    "    n_test_participants = max(1, int(len(participants) * test_size))\n",
    "    np.random.seed(random_state)\n",
    "    test_participants = np.random.choice(participants, n_test_participants, replace=False)\n",
    "    train_participants = np.array([p for p in participants if p not in test_participants])\n",
    "    \n",
    "    # For augmented data, handle original and augmented segments\n",
    "    is_augmented = segment_info['segment_path'].str.contains('_aug\\\\d+\\\\.wav').any()\n",
    "    \n",
    "    if is_augmented:\n",
    "        # Get indices for train and test (including augmented versions)\n",
    "        train_indices = segment_info[\n",
    "            segment_info['participant_id'].isin(train_participants)\n",
    "        ].index\n",
    "        \n",
    "        # For test, only use original (non-augmented) segments from test participants\n",
    "        test_indices = segment_info[\n",
    "            (segment_info['participant_id'].isin(test_participants)) &\n",
    "            (~segment_info['segment_path'].str.contains('_aug\\\\d+\\\\.wav'))\n",
    "        ].index\n",
    "    else:\n",
    "        # Simple split for non-augmented data\n",
    "        train_indices = segment_info[\n",
    "            segment_info['participant_id'].isin(train_participants)\n",
    "        ].index\n",
    "        test_indices = segment_info[\n",
    "            segment_info['participant_id'].isin(test_participants)\n",
    "        ].index\n",
    "    \n",
    "    # Convert to arrays\n",
    "    train_indices = np.array(train_indices)\n",
    "    test_indices = np.array(test_indices)\n",
    "    \n",
    "    # Print split statistics\n",
    "    print(f\"\\nParticipant-Independent Split Statistics:\")\n",
    "    print(f\"Training participants: {sorted(train_participants)}\")\n",
    "    print(f\"Test participants: {sorted(test_participants)}\")\n",
    "    print(f\"\\nTraining set size: {len(train_indices)}\")\n",
    "    print(f\"Test set size: {len(test_indices)}\")\n",
    "    print(\"\\nLabel distribution in training set:\")\n",
    "    print(pd.Series(y[train_indices]).value_counts())\n",
    "    print(\"\\nLabel distribution in test set:\")\n",
    "    print(pd.Series(y[test_indices]).value_counts())\n",
    "    \n",
    "    return (X[train_indices], X[test_indices], \n",
    "            y[train_indices], y[test_indices],\n",
    "            train_indices, test_indices)\n",
    "\n",
    "def train_evaluate_knn_participant_independent(X_train, X_test, y_train, y_test, cv=5):\n",
    "    \"\"\"\n",
    "    Train and evaluate KNN model with participant-independent validation.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: Training and test data\n",
    "        cv (int): Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "        best_model: Trained model with best parameters\n",
    "        best_params: Best hyperparameters\n",
    "        cv_results: Cross-validation results\n",
    "    \"\"\"\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Encode labels\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    # Store label mapping for later use\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(\"\\nLabel mapping:\", label_mapping)\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "    \n",
    "    # Initialize and train model with GridSearchCV\n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Use StratifiedKFold for cross-validation\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    cv_splitter = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        knn, \n",
    "        param_grid, \n",
    "        cv=cv_splitter,\n",
    "        scoring='accuracy', \n",
    "        n_jobs=-1,\n",
    "        error_score=0.0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "    \n",
    "    # Get best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_encoded = best_model.predict(X_test_scaled)\n",
    "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nBest parameters:\", best_params)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title('Confusion Matrix (Participant-Independent)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return best_model, best_params, grid_search.cv_results_\n",
    "\n",
    "def main_participant_independent():\n",
    "    \"\"\"\n",
    "    Main function to run participant-independent evaluation on all feature sets.\n",
    "    \"\"\"\n",
    "    # Define paths for different feature sets\n",
    "    feature_sets = [\n",
    "        {\n",
    "            'name': 'mfcc',\n",
    "            'features_path': '../../extracted_features/features/mfcc_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_env',\n",
    "            'features_path': '../../extracted_features/features/mfcc_env_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_env_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_extracted',\n",
    "            'features_path': '../../extracted_features/features/mfcc_extracted_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_extracted_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_aug',\n",
    "            'features_path': '../../extracted_features/features/mfcc_features_aug.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_labels_aug.npy',\n",
    "            'segment_info_path': '../../segment_info/augmented_segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_env_aug',\n",
    "            'features_path': '../../extracted_features/features/mfcc_env_aug_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_env_aug_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/augmented_segment_info.csv'\n",
    "        },\n",
    "        {\n",
    "            'name': 'mfcc_extracted_aug',\n",
    "            'features_path': '../../extracted_features/features/mfcc_extracted_aug_features.npy',\n",
    "            'labels_path': '../../extracted_features/labels/mfcc_extracted_aug_labels.npy',\n",
    "            'segment_info_path': '../../segment_info/augmented_segment_info.csv'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for feature_set in feature_sets:\n",
    "        print(f\"\\nProcessing {feature_set['name']} features...\")\n",
    "        \n",
    "        # Load data\n",
    "        X, y, segment_info = load_features_and_labels(\n",
    "            feature_set['features_path'],\n",
    "            feature_set['labels_path'],\n",
    "            feature_set['segment_info_path']\n",
    "        )\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test, train_idx, test_idx = \\\n",
    "            participant_independent_split(X, y, segment_info)\n",
    "        \n",
    "        # Train and evaluate\n",
    "        best_model, best_params, cv_results = train_evaluate_knn_participant_independent(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[feature_set['name']] = {\n",
    "            'best_model': best_model,\n",
    "            'best_params': best_params,\n",
    "            'cv_results': cv_results,\n",
    "            'test_indices': test_idx\n",
    "        }\n",
    "        \n",
    "        # Save confusion matrix plot\n",
    "        plt.savefig(f\"../../visualization/confusion_matrix_participant_independent_{feature_set['name']}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main_participant_independent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
