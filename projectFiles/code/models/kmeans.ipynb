{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def cluster_sounds(n_clusters=4, features_path='features', output_dir=''):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on MFCC features\n",
    "    \"\"\"\n",
    "    # Load the MFCC features\n",
    "    # features_path = Path('../projectFiles/features')\n",
    "    # X = np.load(features_path / 'mfcc_features.npy')\n",
    "    \n",
    "    X = np.load(features_path)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"Performing K-means clustering with {n_clusters} clusters...\")\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Save cluster assignments\n",
    "    # if features_path == 'features/mfcc_features_augmented.npy':\n",
    "    #     np.save('features/cluster_labels_augmented.npy', cluster_labels)\n",
    "    # if features_path == 'features/mfcc_features.npy':\n",
    "    #     np.save('features/cluster_labels.npy', cluster_labels)\n",
    "    # if features_path == 'features/mfcc_features_expanded.npy':\n",
    "    #     np.save('features/cluster_labels_expanded.npy', cluster_labels)\n",
    "    # else:\n",
    "    #     np.save('features/cluster_labels_expanded_augmented.npy', cluster_labels)\n",
    "        \n",
    "    # if features_path == 'features/mfcc_features_optimized.npy':\n",
    "    #     np.save('features/cluster_labels_optimized.npy', cluster_labels)\n",
    "    # if features_path == 'features/mfcc_features_optimized_augmented.npy':\n",
    "    #     np.save('features/cluster_labels_optimized_augmented.npy', cluster_labels)\n",
    "        \n",
    "    np.save(output_dir, cluster_labels)\n",
    "    \n",
    "    # Print cluster sizes\n",
    "    print(\"\\nCluster sizes:\")\n",
    "    for i in range(n_clusters):\n",
    "        print(f\"Cluster {i}: {np.sum(cluster_labels == i)} sounds\")\n",
    "    \n",
    "    return cluster_labels, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing K-means clustering with 4 clusters...\n",
      "\n",
      "Cluster sizes:\n",
      "Cluster 0: 1026 sounds\n",
      "Cluster 1: 1522 sounds\n",
      "Cluster 2: 1992 sounds\n",
      "Cluster 3: 1174 sounds\n",
      "Performing K-means clustering with 4 clusters...\n",
      "\n",
      "Cluster sizes:\n",
      "Cluster 0: 8413 sounds\n",
      "Cluster 1: 9337 sounds\n",
      "Cluster 2: 10910 sounds\n",
      "Cluster 3: 5624 sounds\n",
      "Performing K-means clustering with 4 clusters...\n",
      "\n",
      "Cluster sizes:\n",
      "Cluster 0: 1582 sounds\n",
      "Cluster 1: 965 sounds\n",
      "Cluster 2: 1307 sounds\n",
      "Cluster 3: 1860 sounds\n",
      "Performing K-means clustering with 4 clusters...\n",
      "\n",
      "Cluster sizes:\n",
      "Cluster 0: 7885 sounds\n",
      "Cluster 1: 5408 sounds\n",
      "Cluster 2: 11225 sounds\n",
      "Cluster 3: 9766 sounds\n",
      "Performing K-means clustering with 4 clusters...\n",
      "\n",
      "Cluster sizes:\n",
      "Cluster 0: 1428 sounds\n",
      "Cluster 1: 941 sounds\n",
      "Cluster 2: 1311 sounds\n",
      "Cluster 3: 2034 sounds\n",
      "Performing K-means clustering with 4 clusters...\n",
      "\n",
      "Cluster sizes:\n",
      "Cluster 0: 8473 sounds\n",
      "Cluster 1: 11840 sounds\n",
      "Cluster 2: 3115 sounds\n",
      "Cluster 3: 10856 sounds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('../../cluster_assignments', exist_ok=True)\n",
    "\n",
    "cluster_labels_mfcc, kmeans_model_mfcc = cluster_sounds(n_clusters=4, features_path='../../extracted_features/features/mfcc_features.npy', output_dir='../../cluster_assignments/mfcc_cluster.npy')\n",
    "\n",
    "cluster_labels_mfcc_aug, kmeans_model_mfcc_aug = cluster_sounds(n_clusters=4, features_path='../../extracted_features/features/mfcc_features_aug.npy', output_dir='../../cluster_assignments/mfcc_aug_cluster.npy')\n",
    "\n",
    "cluster_labels_env, kmeans_model_env = cluster_sounds(n_clusters=4, features_path='../../extracted_features/features/mfcc_env_features.npy', output_dir='../../cluster_assignments/mfcc_env_cluster.npy')\n",
    "\n",
    "cluster_labels_env_aug, kmeans_model_env_aug = cluster_sounds(n_clusters=4, features_path='../../extracted_features/features/mfcc_env_aug_features.npy', output_dir='../../cluster_assignments/mfcc_env_aug_cluster.npy')\n",
    "\n",
    "cluster_labels_extracted, kmeans_model_extracted = cluster_sounds(n_clusters=4, features_path='../../extracted_features/features/mfcc_extracted_features.npy', output_dir='../../cluster_assignments/mfcc_extracted_cluster.npy')\n",
    "\n",
    "cluster_labels_extracted_aug, kmeans_model_extracted_aug = cluster_sounds(n_clusters=4, features_path='../../extracted_features/features/mfcc_extracted_aug_features.npy', output_dir='../../cluster_assignments/mfcc_extracted_aug_cluster.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating K-Means Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_clustering(features_path='features', labels_path='labels.npy', cluster_labels_path='cluster_labels.npy', viz_dir=''):\n",
    "    \"\"\"\n",
    "    Evaluate clustering results using both internal and external metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # features_path = Path('../projectFiles/features')\n",
    "    X = np.load(features_path)\n",
    "    y_true = np.load(labels_path)\n",
    "    cluster_labels = np.load(cluster_labels_path)\n",
    "    \n",
    "    # Standardize features (same as in clustering)\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    silhouette = silhouette_score(X_scaled, cluster_labels)\n",
    "    davies_bouldin = davies_bouldin_score(X_scaled, cluster_labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(X_scaled, cluster_labels)\n",
    "    \n",
    "    print(\"Internal Metrics:\")\n",
    "    print(f\"Silhouette Score: {silhouette:.3f} (ranges from -1 to 1, higher is better)\")\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin:.3f} (lower is better)\")\n",
    "    print(f\"Calinski-Harabasz Index: {calinski_harabasz:.3f} (higher is better)\")\n",
    "    \n",
    "    ari = adjusted_rand_score(y_true, cluster_labels)\n",
    "    nmi = normalized_mutual_info_score(y_true, cluster_labels)\n",
    "    \n",
    "    print(\"\\nExternal Metrics:\")\n",
    "    print(f\"Adjusted Rand Index: {ari:.3f} (ranges from -1 to 1, higher is better)\")\n",
    "    print(f\"Normalized Mutual Information: {nmi:.3f} (ranges from 0 to 1, higher is better)\")\n",
    "    \n",
    "    unique_labels = np.unique(y_true)\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    confusion_matrix = np.zeros((len(unique_labels), len(unique_clusters)))\n",
    "    \n",
    "    for i, label in enumerate(unique_labels):\n",
    "        for j, cluster in enumerate(unique_clusters):\n",
    "            confusion_matrix[i, j] = np.sum((y_true == label) & (cluster_labels == cluster))\n",
    "    \n",
    "    # Normalize by row (true labels)\n",
    "    confusion_matrix_normalized = confusion_matrix / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_matrix_normalized, \n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                xticklabels=[f'Cluster {i}' for i in range(len(unique_clusters))],\n",
    "                yticklabels=unique_labels,\n",
    "                cmap='YlOrRd')\n",
    "    plt.title('Normalized Confusion Matrix:\\nTrue Labels vs Cluster Assignments')\n",
    "    plt.xlabel('Predicted Cluster')\n",
    "    plt.ylabel('True Label')\n",
    "    \n",
    "    # Save confusion matrix\n",
    "    # viz_dir = Path(features_path).parent.parent / 'visualization'\n",
    "    # viz_dir.mkdir(exist_ok=True, parents=True)\n",
    "    # if features_path == 'features/mfcc_features_augmented.npy':\n",
    "    #     plt.savefig(viz_dir / 'confusion_matrix_augmented.png', dpi=300, bbox_inches='tight')\n",
    "    # if features_path == 'features/mfcc_features_expanded.npy':\n",
    "    #     plt.savefig(viz_dir / 'confusion_matrix_expanded.png', dpi=300, bbox_inches='tight')\n",
    "    # if features_path == 'features/mfcc_features_expanded_augmented.npy':\n",
    "    #     plt.savefig(viz_dir / 'confusion_matrix_expanded_augmented.png', dpi=300, bbox_inches='tight')\n",
    "    # else:\n",
    "    #     plt.savefig(viz_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Ensure the directory exists before saving\n",
    "    os.makedirs(os.path.dirname(viz_dir), exist_ok=True)\n",
    "    plt.savefig(viz_dir, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nCluster Composition:\")\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_mask = cluster_labels == cluster\n",
    "        print(f\"\\nCluster {cluster}:\")\n",
    "        for label in unique_labels:\n",
    "            count = np.sum((y_true == label) & cluster_mask)\n",
    "            percentage = (count / np.sum(cluster_mask)) * 100\n",
    "            print(f\"{label}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "    return {\n",
    "        'silhouette': silhouette,\n",
    "        'davies_bouldin': davies_bouldin,\n",
    "        'calinski_harabasz': calinski_harabasz,\n",
    "        'ari': ari,\n",
    "        'nmi': nmi,\n",
    "        'confusion_matrix': confusion_matrix,\n",
    "        'confusion_matrix_normalized': confusion_matrix_normalized\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Metrics:\n",
      "Silhouette Score: 0.120 (ranges from -1 to 1, higher is better)\n",
      "Davies-Bouldin Index: 2.136 (lower is better)\n",
      "Calinski-Harabasz Index: 611.699 (higher is better)\n",
      "\n",
      "External Metrics:\n",
      "Adjusted Rand Index: 0.108 (ranges from -1 to 1, higher is better)\n",
      "Normalized Mutual Information: 0.115 (ranges from 0 to 1, higher is better)\n",
      "\n",
      "Cluster Composition:\n",
      "\n",
      "Cluster 0:\n",
      "hhc: 174 samples (17.0%)\n",
      "hho: 312 samples (30.4%)\n",
      "kd: 125 samples (12.2%)\n",
      "sd: 415 samples (40.4%)\n",
      "\n",
      "Cluster 1:\n",
      "hhc: 288 samples (18.9%)\n",
      "hho: 115 samples (7.6%)\n",
      "kd: 951 samples (62.5%)\n",
      "sd: 168 samples (11.0%)\n",
      "\n",
      "Cluster 2:\n",
      "hhc: 519 samples (26.1%)\n",
      "hho: 184 samples (9.2%)\n",
      "kd: 596 samples (29.9%)\n",
      "sd: 693 samples (34.8%)\n",
      "\n",
      "Cluster 3:\n",
      "hhc: 517 samples (44.0%)\n",
      "hho: 398 samples (33.9%)\n",
      "kd: 104 samples (8.9%)\n",
      "sd: 155 samples (13.2%)\n"
     ]
    }
   ],
   "source": [
    "evaluation_results_mfcc = evaluate_clustering(features_path='../../extracted_features/features/mfcc_features.npy', labels_path='../../extracted_features/labels/mfcc_labels.npy', cluster_labels_path='../../cluster_assignments/mfcc_cluster.npy', viz_dir='../../visualization/clustering_eval/mfcc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Metrics:\n",
      "Silhouette Score: 0.118 (ranges from -1 to 1, higher is better)\n",
      "Davies-Bouldin Index: 2.220 (lower is better)\n",
      "Calinski-Harabasz Index: 3987.355 (higher is better)\n",
      "\n",
      "External Metrics:\n",
      "Adjusted Rand Index: 0.077 (ranges from -1 to 1, higher is better)\n",
      "Normalized Mutual Information: 0.077 (ranges from 0 to 1, higher is better)\n",
      "\n",
      "Cluster Composition:\n",
      "\n",
      "Cluster 0:\n",
      "hhc: 1432 samples (17.0%)\n",
      "hho: 723 samples (8.6%)\n",
      "kd: 5304 samples (63.0%)\n",
      "sd: 954 samples (11.3%)\n",
      "\n",
      "Cluster 1:\n",
      "hhc: 3181 samples (34.1%)\n",
      "hho: 2769 samples (29.7%)\n",
      "kd: 1111 samples (11.9%)\n",
      "sd: 2276 samples (24.4%)\n",
      "\n",
      "Cluster 2:\n",
      "hhc: 2652 samples (24.3%)\n",
      "hho: 1229 samples (11.3%)\n",
      "kd: 3114 samples (28.5%)\n",
      "sd: 3915 samples (35.9%)\n",
      "\n",
      "Cluster 3:\n",
      "hhc: 1723 samples (30.6%)\n",
      "hho: 1333 samples (23.7%)\n",
      "kd: 1127 samples (20.0%)\n",
      "sd: 1441 samples (25.6%)\n"
     ]
    }
   ],
   "source": [
    "evaluation_results_mfcc_aug = evaluate_clustering(features_path='../../extracted_features/features/mfcc_features_aug.npy', labels_path='../../extracted_features/labels/mfcc_labels_aug.npy', cluster_labels_path='../../cluster_assignments/mfcc_aug_cluster.npy', viz_dir='../../visualization/clustering_eval/mfcc_aug.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Metrics:\n",
      "Silhouette Score: 0.075 (ranges from -1 to 1, higher is better)\n",
      "Davies-Bouldin Index: 3.063 (lower is better)\n",
      "Calinski-Harabasz Index: 365.253 (higher is better)\n",
      "\n",
      "External Metrics:\n",
      "Adjusted Rand Index: 0.100 (ranges from -1 to 1, higher is better)\n",
      "Normalized Mutual Information: 0.112 (ranges from 0 to 1, higher is better)\n",
      "\n",
      "Cluster Composition:\n",
      "\n",
      "Cluster 0:\n",
      "hhc: 572 samples (36.2%)\n",
      "hho: 349 samples (22.1%)\n",
      "kd: 156 samples (9.9%)\n",
      "sd: 505 samples (31.9%)\n",
      "\n",
      "Cluster 1:\n",
      "hhc: 199 samples (20.6%)\n",
      "hho: 347 samples (36.0%)\n",
      "kd: 69 samples (7.2%)\n",
      "sd: 350 samples (36.3%)\n",
      "\n",
      "Cluster 2:\n",
      "hhc: 175 samples (13.4%)\n",
      "hho: 94 samples (7.2%)\n",
      "kd: 911 samples (69.7%)\n",
      "sd: 127 samples (9.7%)\n",
      "\n",
      "Cluster 3:\n",
      "hhc: 552 samples (29.7%)\n",
      "hho: 219 samples (11.8%)\n",
      "kd: 640 samples (34.4%)\n",
      "sd: 449 samples (24.1%)\n"
     ]
    }
   ],
   "source": [
    "evaluation_results_mfcc_env = evaluate_clustering(features_path='../../extracted_features/features/mfcc_env_features.npy', labels_path='../../extracted_features/labels/mfcc_env_labels.npy', cluster_labels_path='../../cluster_assignments/mfcc_env_cluster.npy', viz_dir='../../visualization/clustering_eval/mfcc_env.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Metrics:\n",
      "Silhouette Score: 0.078 (ranges from -1 to 1, higher is better)\n",
      "Davies-Bouldin Index: 2.811 (lower is better)\n",
      "Calinski-Harabasz Index: 2359.465 (higher is better)\n",
      "\n",
      "External Metrics:\n",
      "Adjusted Rand Index: 0.082 (ranges from -1 to 1, higher is better)\n",
      "Normalized Mutual Information: 0.088 (ranges from 0 to 1, higher is better)\n",
      "\n",
      "Cluster Composition:\n",
      "\n",
      "Cluster 0:\n",
      "hhc: 1061 samples (13.5%)\n",
      "hho: 714 samples (9.1%)\n",
      "kd: 5315 samples (67.4%)\n",
      "sd: 795 samples (10.1%)\n",
      "\n",
      "Cluster 1:\n",
      "hhc: 1747 samples (32.3%)\n",
      "hho: 1497 samples (27.7%)\n",
      "kd: 604 samples (11.2%)\n",
      "sd: 1560 samples (28.8%)\n",
      "\n",
      "Cluster 2:\n",
      "hhc: 3091 samples (27.5%)\n",
      "hho: 1644 samples (14.6%)\n",
      "kd: 3734 samples (33.3%)\n",
      "sd: 2756 samples (24.6%)\n",
      "\n",
      "Cluster 3:\n",
      "hhc: 3089 samples (31.6%)\n",
      "hho: 2199 samples (22.5%)\n",
      "kd: 1003 samples (10.3%)\n",
      "sd: 3475 samples (35.6%)\n"
     ]
    }
   ],
   "source": [
    "evaluation_results_mfcc_env_aug = evaluate_clustering(features_path='../../extracted_features/features/mfcc_env_aug_features.npy', labels_path='../../extracted_features/labels/mfcc_env_aug_labels.npy', cluster_labels_path='../../cluster_assignments/mfcc_env_aug_cluster.npy', viz_dir='../../visualization/clustering_eval/mfcc_env_aug.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Metrics:\n",
      "Silhouette Score: 0.132 (ranges from -1 to 1, higher is better)\n",
      "Davies-Bouldin Index: 2.148 (lower is better)\n",
      "Calinski-Harabasz Index: 796.187 (higher is better)\n",
      "\n",
      "External Metrics:\n",
      "Adjusted Rand Index: 0.107 (ranges from -1 to 1, higher is better)\n",
      "Normalized Mutual Information: 0.112 (ranges from 0 to 1, higher is better)\n",
      "\n",
      "Cluster Composition:\n",
      "\n",
      "Cluster 0:\n",
      "hhc: 203 samples (14.2%)\n",
      "hho: 127 samples (8.9%)\n",
      "kd: 474 samples (33.2%)\n",
      "sd: 624 samples (43.7%)\n",
      "\n",
      "Cluster 1:\n",
      "hhc: 291 samples (30.9%)\n",
      "hho: 187 samples (19.9%)\n",
      "kd: 238 samples (25.3%)\n",
      "sd: 225 samples (23.9%)\n",
      "\n",
      "Cluster 2:\n",
      "hhc: 205 samples (15.6%)\n",
      "hho: 100 samples (7.6%)\n",
      "kd: 873 samples (66.6%)\n",
      "sd: 133 samples (10.1%)\n",
      "\n",
      "Cluster 3:\n",
      "hhc: 799 samples (39.3%)\n",
      "hho: 595 samples (29.3%)\n",
      "kd: 191 samples (9.4%)\n",
      "sd: 449 samples (22.1%)\n"
     ]
    }
   ],
   "source": [
    "evaluation_results_mfcc_extracted = evaluate_clustering(features_path='../../extracted_features/features/mfcc_extracted_features.npy', labels_path='../../extracted_features/labels/mfcc_extracted_labels.npy', cluster_labels_path='../../cluster_assignments/mfcc_extracted_cluster.npy', viz_dir='../../visualization/clustering_eval/mfcc_extracted.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Metrics:\n",
      "Silhouette Score: 0.133 (ranges from -1 to 1, higher is better)\n",
      "Davies-Bouldin Index: 2.182 (lower is better)\n",
      "Calinski-Harabasz Index: 4725.724 (higher is better)\n",
      "\n",
      "External Metrics:\n",
      "Adjusted Rand Index: 0.088 (ranges from -1 to 1, higher is better)\n",
      "Normalized Mutual Information: 0.090 (ranges from 0 to 1, higher is better)\n",
      "\n",
      "Cluster Composition:\n",
      "\n",
      "Cluster 0:\n",
      "hhc: 1162 samples (13.7%)\n",
      "hho: 703 samples (8.3%)\n",
      "kd: 5541 samples (65.4%)\n",
      "sd: 1067 samples (12.6%)\n",
      "\n",
      "Cluster 1:\n",
      "hhc: 4375 samples (37.0%)\n",
      "hho: 3282 samples (27.7%)\n",
      "kd: 1187 samples (10.0%)\n",
      "sd: 2996 samples (25.3%)\n",
      "\n",
      "Cluster 2:\n",
      "hhc: 1007 samples (32.3%)\n",
      "hho: 527 samples (16.9%)\n",
      "kd: 560 samples (18.0%)\n",
      "sd: 1021 samples (32.8%)\n",
      "\n",
      "Cluster 3:\n",
      "hhc: 2444 samples (22.5%)\n",
      "hho: 1542 samples (14.2%)\n",
      "kd: 3368 samples (31.0%)\n",
      "sd: 3502 samples (32.3%)\n"
     ]
    }
   ],
   "source": [
    "evaluation_results_mfcc_extracted_aug = evaluate_clustering(features_path='../../extracted_features/features/mfcc_extracted_aug_features.npy', labels_path='../../extracted_features/labels/mfcc_extracted_aug_labels.npy', cluster_labels_path='../../cluster_assignments/mfcc_extracted_aug_cluster.npy', viz_dir='../../visualization/clustering_eval/mfcc_extracted_aug.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing for MFCC Basic...\n",
      "Performing cross-validation and hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Results:\n",
      "Optimal number of clusters: 8\n",
      "\n",
      "Metrics at optimal k:\n",
      "Silhouette Score: 0.118\n",
      "Calinski-Harabasz Score: 93.825\n",
      "Adjusted Rand Index: 0.082\n",
      "Normalized Mutual Information: 0.133\n",
      "\n",
      "Optimizing for MFCC + Envelope...\n",
      "Performing cross-validation and hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Results:\n",
      "Optimal number of clusters: 3\n",
      "\n",
      "Metrics at optimal k:\n",
      "Silhouette Score: 0.080\n",
      "Calinski-Harabasz Score: 88.913\n",
      "Adjusted Rand Index: 0.090\n",
      "Normalized Mutual Information: 0.106\n",
      "\n",
      "Optimizing for MFCC Optimized...\n",
      "Performing cross-validation and hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Results:\n",
      "Optimal number of clusters: 6\n",
      "\n",
      "Metrics at optimal k:\n",
      "Silhouette Score: 0.133\n",
      "Calinski-Harabasz Score: 137.563\n",
      "Adjusted Rand Index: 0.113\n",
      "Normalized Mutual Information: 0.126\n",
      "\n",
      "Optimizing for MFCC Basic Augmented...\n",
      "Performing cross-validation and hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:21<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Results:\n",
      "Optimal number of clusters: 4\n",
      "\n",
      "Metrics at optimal k:\n",
      "Silhouette Score: 0.119\n",
      "Calinski-Harabasz Score: 770.088\n",
      "Adjusted Rand Index: 0.070\n",
      "Normalized Mutual Information: 0.070\n",
      "\n",
      "Optimizing for MFCC + Envelope Augmented...\n",
      "Performing cross-validation and hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:19<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Results:\n",
      "Optimal number of clusters: 4\n",
      "\n",
      "Metrics at optimal k:\n",
      "Silhouette Score: 0.078\n",
      "Calinski-Harabasz Score: 472.313\n",
      "Adjusted Rand Index: 0.083\n",
      "Normalized Mutual Information: 0.089\n",
      "\n",
      "Optimizing for MFCC Optimized Augmented...\n",
      "Performing cross-validation and hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Results:\n",
      "Optimal number of clusters: 7\n",
      "\n",
      "Metrics at optimal k:\n",
      "Silhouette Score: 0.128\n",
      "Calinski-Harabasz Score: 736.366\n",
      "Adjusted Rand Index: 0.120\n",
      "Normalized Mutual Information: 0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "def optimize_kmeans(features_path, labels_path, n_splits=5, min_clusters=2, max_clusters=8):\n",
    "    \"\"\"\n",
    "    Perform k-means optimization using cross-validation and hyperparameter tuning\n",
    "    \n",
    "    Args:\n",
    "        features_path: Path to features .npy file\n",
    "        labels_path: Path to labels .npy file\n",
    "        n_splits: Number of cross-validation folds\n",
    "        min_clusters: Minimum number of clusters to try\n",
    "        max_clusters: Maximum number of clusters to try\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.load(features_path)\n",
    "    y = np.load(labels_path)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store results\n",
    "    results = {\n",
    "        'n_clusters': [],\n",
    "        'silhouette_scores': [],\n",
    "        'ari_scores': [],\n",
    "        'nmi_scores': [],\n",
    "        'calinski_scores': []\n",
    "    }\n",
    "    \n",
    "    print(\"Performing cross-validation and hyperparameter tuning...\")\n",
    "    # Try different numbers of clusters\n",
    "    for n_clusters in tqdm(range(min_clusters, max_clusters + 1)):\n",
    "        fold_silhouette = []\n",
    "        fold_ari = []\n",
    "        fold_nmi = []\n",
    "        fold_calinski = []\n",
    "        \n",
    "        # Cross validation\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
    "            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            # Train KMeans\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            train_clusters = kmeans.fit_predict(X_train)\n",
    "            val_clusters = kmeans.predict(X_val)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            fold_silhouette.append(silhouette_score(X_val, val_clusters))\n",
    "            fold_ari.append(adjusted_rand_score(y_val, val_clusters))\n",
    "            fold_nmi.append(normalized_mutual_info_score(y_val, val_clusters))\n",
    "            fold_calinski.append(calinski_harabasz_score(X_val, val_clusters))\n",
    "        \n",
    "        # Store average results\n",
    "        results['n_clusters'].append(n_clusters)\n",
    "        results['silhouette_scores'].append(np.mean(fold_silhouette))\n",
    "        results['ari_scores'].append(np.mean(fold_ari))\n",
    "        results['nmi_scores'].append(np.mean(fold_nmi))\n",
    "        results['calinski_scores'].append(np.mean(fold_calinski))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(results['n_clusters'], results['silhouette_scores'], 'o-', label='Silhouette Score')\n",
    "    plt.plot(results['n_clusters'], np.array(results['calinski_scores'])/max(results['calinski_scores']), \n",
    "             'o-', label='Normalized Calinski-Harabasz')\n",
    "    plt.title('Internal Clustering Metrics vs Number of Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(results['n_clusters'], results['ari_scores'], 'o-', label='Adjusted Rand Index')\n",
    "    plt.plot(results['n_clusters'], results['nmi_scores'], 'o-', label='Normalized Mutual Information')\n",
    "    plt.title('External Clustering Metrics vs Number of Clusters')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    os.makedirs('../../visualization/optimization', exist_ok=True)\n",
    "    plt.savefig('../../visualization/optimization/kmeans_optimization.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Find optimal number of clusters\n",
    "    # We'll use a weighted sum of normalized metrics\n",
    "    normalized_metrics = {\n",
    "        'silhouette': (np.array(results['silhouette_scores']) - min(results['silhouette_scores'])) / \n",
    "                     (max(results['silhouette_scores']) - min(results['silhouette_scores'])),\n",
    "        'calinski': np.array(results['calinski_scores']) / max(results['calinski_scores']),\n",
    "        'ari': (np.array(results['ari_scores']) - min(results['ari_scores'])) /\n",
    "               (max(results['ari_scores']) - min(results['ari_scores'])),\n",
    "        'nmi': (np.array(results['nmi_scores']) - min(results['nmi_scores'])) /\n",
    "               (max(results['nmi_scores']) - min(results['nmi_scores']))\n",
    "    }\n",
    "    \n",
    "    # Weighted sum (you can adjust weights based on importance)\n",
    "    weights = {'silhouette': 0.3, 'calinski': 0.2, 'ari': 0.25, 'nmi': 0.25}\n",
    "    combined_scores = sum(weights[metric] * normalized_metrics[metric] \n",
    "                        for metric in weights.keys())\n",
    "    \n",
    "    optimal_k = results['n_clusters'][np.argmax(combined_scores)]\n",
    "    \n",
    "    print(\"\\nOptimization Results:\")\n",
    "    print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "    print(\"\\nMetrics at optimal k:\")\n",
    "    print(f\"Silhouette Score: {results['silhouette_scores'][optimal_k-min_clusters]:.3f}\")\n",
    "    print(f\"Calinski-Harabasz Score: {results['calinski_scores'][optimal_k-min_clusters]:.3f}\")\n",
    "    print(f\"Adjusted Rand Index: {results['ari_scores'][optimal_k-min_clusters]:.3f}\")\n",
    "    print(f\"Normalized Mutual Information: {results['nmi_scores'][optimal_k-min_clusters]:.3f}\")\n",
    "    \n",
    "    return optimal_k, results\n",
    "\n",
    "# Use the function for different feature sets\n",
    "feature_sets = [\n",
    "    {\n",
    "        'name': 'MFCC Basic',\n",
    "        'features': '../../extracted_features/features/mfcc_features.npy',\n",
    "        'labels': '../../extracted_features/labels/mfcc_labels.npy',\n",
    "        'output': '../../cluster_assignments/hdbscan/hdbscan_mfcc_cluster.npy',\n",
    "        'viz': '../../visualization/clustering_eval/hdbscan/hdbscan_mfcc.png'\n",
    "    },\n",
    "    {\n",
    "        'name': 'MFCC + Envelope',\n",
    "        'features': '../../extracted_features/features/mfcc_env_features.npy',\n",
    "        'labels': '../../extracted_features/labels/mfcc_env_labels.npy',\n",
    "        'output': '../../cluster_assignments/hdbscan/hdbscan_mfcc_env_cluster.npy',\n",
    "        'viz': '../../visualization/clustering_eval/hdbscan/hdbscan_mfcc_env.png'\n",
    "    },\n",
    "    {\n",
    "        'name': 'MFCC Optimized',\n",
    "        'features': '../../extracted_features/features/mfcc_extracted_features.npy',\n",
    "        'labels': '../../extracted_features/labels/mfcc_extracted_labels.npy',\n",
    "        'output': '../../cluster_assignments/hdbscan/hdbscan_mfcc_extracted_cluster.npy',\n",
    "        'viz': '../../visualization/clustering_eval/hdbscan/hdbscan_mfcc_extracted.png'\n",
    "    },\n",
    "    {\n",
    "        'name': 'MFCC Basic Augmented',\n",
    "        'features': '../../extracted_features/features/mfcc_features_aug.npy',\n",
    "        'labels': '../../extracted_features/labels/mfcc_labels_aug.npy',\n",
    "        'output': '../../cluster_assignments/hdbscan/hdbscan_mfcc_aug_cluster.npy',\n",
    "        'viz': '../../visualization/clustering_eval/hdbscan/hdbscan_mfcc_aug.png'\n",
    "    },\n",
    "    {\n",
    "        'name': 'MFCC + Envelope Augmented',\n",
    "        'features': '../../extracted_features/features/mfcc_env_aug_features.npy',\n",
    "        'labels': '../../extracted_features/labels/mfcc_env_aug_labels.npy',\n",
    "        'output': '../../cluster_assignments/hdbscan/hdbscan_mfcc_env_aug_cluster.npy',\n",
    "        'viz': '../../visualization/clustering_eval/hdbscan/hdbscan_mfcc_env_aug.png'\n",
    "    },\n",
    "    {\n",
    "        'name': 'MFCC Optimized Augmented',\n",
    "        'features': '../../extracted_features/features/mfcc_extracted_aug_features.npy',\n",
    "        'labels': '../../extracted_features/labels/mfcc_extracted_aug_labels.npy',\n",
    "        'output': '../../cluster_assignments/hdbscan/hdbscan_mfcc_extracted_aug_cluster.npy',\n",
    "        'viz': '../../visualization/clustering_eval/hdbscan/hdbscan_mfcc_extracted_aug.png'\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "# Run optimization for each feature set\n",
    "optimization_results = {}\n",
    "for feature_set in feature_sets:\n",
    "    print(f\"\\nOptimizing for {feature_set['name']}...\")\n",
    "    optimal_k, results = optimize_kmeans(\n",
    "        feature_set['features'],\n",
    "        feature_set['labels'],\n",
    "        min_clusters=2,\n",
    "        max_clusters=8\n",
    "    )\n",
    "    optimization_results[feature_set['name']] = {\n",
    "        'optimal_k': optimal_k,\n",
    "        'results': results\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
