{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import os\n",
    "from pathlib import Path\n",
    "import platform\n",
    "from torch.amp import autocast, GradScaler  # Updated import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found NVIDIA RTX 4090: NVIDIA GeForce RTX 4090\n",
      "\n",
      "Detailed Participant Analysis:\n",
      "AVP Dataset (28 participants):\n",
      "['P1', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18', 'P19', 'P2', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9']\n",
      "\n",
      "LVT Dataset (20 participants):\n",
      "AFR: IP\n",
      "AZi: IP\n",
      "Bea: IP\n",
      "Bic: IP\n",
      "Cat: IP\n",
      "Cav: IP\n",
      "Cra: IP\n",
      "Isa: IP\n",
      "JOl: IP\n",
      "JSi: IP\n",
      "JSo: IP\n",
      "MCo: IP\n",
      "Maf: IP\n",
      "Mar: IP\n",
      "Nor: IP\n",
      "Ric: IP\n",
      "Rob: IP\n",
      "Sof: IP\n",
      "Zga: IP\n",
      "Ziz: IP\n",
      "\n",
      "Total unique participants: 48\n",
      "- AVP Dataset: 28 participants\n",
      "- LVT Dataset: 20 participants\n",
      "\n",
      "Fold 1/5\n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, segment_info_path, transform=None, train=True):\n",
    "        self.df = pd.read_csv(segment_info_path)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        \n",
    "        # Standardize JSo/JoS naming\n",
    "        self.df['participant_id'] = self.df['participant_id'].replace('JoSP', 'JSoP')\n",
    "        \n",
    "        self.label_to_id = {'hhc': 0, 'hho': 1, 'kd': 2, 'sd': 3}\n",
    "        \n",
    "        # Parameters for mel spectrogram (as per paper)\n",
    "        self.sample_rate = 16000\n",
    "        self.n_mels = 128\n",
    "        self.n_fft = 1024\n",
    "        self.hop_length = 512\n",
    "        \n",
    "        # Parameters for augmentation (10x as per paper)\n",
    "        self.pitch_shifts = [-2, -1, 0, 1, 2]  # 5 pitch shifts\n",
    "        self.time_stretches = [0.9, 0.95, 1.0, 1.05, 1.1]  # 5 time stretches\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.df) * len(self.pitch_shifts) * len(self.time_stretches)\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _load_and_process_audio(self, audio_path, pitch_shift=0, time_stretch=1.0):\n",
    "        \"\"\"Load and process audio following paper's normalization\"\"\"\n",
    "        # Fix path if needed\n",
    "        if audio_path.startswith('../'):\n",
    "            audio_path = f\"../{audio_path}\"\n",
    "            \n",
    "        # Load audio\n",
    "        y, sr = librosa.load(audio_path, sr=self.sample_rate)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if time_stretch != 1.0:\n",
    "            y = librosa.effects.time_stretch(y, rate=time_stretch)\n",
    "        if pitch_shift != 0:\n",
    "            y = librosa.effects.pitch_shift(y, sr=sr, n_steps=pitch_shift)\n",
    "            \n",
    "        # Compute mel spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=self.n_mels, n_fft=self.n_fft, hop_length=self.hop_length\n",
    "        )\n",
    "        \n",
    "        # Convert to log scale\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "        \n",
    "        # Min-max normalize each patch to [0, 1] as per paper\n",
    "        log_mel_spec = (log_mel_spec - log_mel_spec.min()) / (log_mel_spec.max() - log_mel_spec.min())\n",
    "        \n",
    "        # Convert to tensor and ensure fixed size (128 x 64)\n",
    "        spec_tensor = torch.FloatTensor(log_mel_spec)\n",
    "        target_length = 64\n",
    "        current_length = spec_tensor.size(1)\n",
    "        \n",
    "        if current_length < target_length:\n",
    "            pad_amount = target_length - current_length\n",
    "            spec_tensor = torch.nn.functional.pad(spec_tensor, (0, pad_amount))\n",
    "        elif current_length > target_length:\n",
    "            start = (current_length - target_length) // 2\n",
    "            spec_tensor = spec_tensor[:, start:start + target_length]\n",
    "        \n",
    "        return spec_tensor\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            n_augs = len(self.pitch_shifts) * len(self.time_stretches)\n",
    "            orig_idx = idx // n_augs\n",
    "            aug_idx = idx % n_augs\n",
    "            pitch_idx = aug_idx // len(self.time_stretches)\n",
    "            time_idx = aug_idx % len(self.time_stretches)\n",
    "            \n",
    "            pitch_shift = self.pitch_shifts[pitch_idx]\n",
    "            time_stretch = self.time_stretches[time_idx]\n",
    "        else:\n",
    "            orig_idx = idx\n",
    "            pitch_shift = 0\n",
    "            time_stretch = 1.0\n",
    "            \n",
    "        row = self.df.iloc[orig_idx]\n",
    "        audio_path = row['segment_path']\n",
    "        label = self.label_to_id[row['instrument_label']]\n",
    "        participant = row['participant_id']\n",
    "        \n",
    "        spec = self._load_and_process_audio(audio_path, pitch_shift, time_stretch)\n",
    "        return spec, label, participant\n",
    "\n",
    "class DrumCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4, embedding_dim=1024):\n",
    "        super(DrumCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 64 x 64 x 32\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 128 x 32 x 16\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 256 x 16 x 8\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)   # 512 x 8 x 4\n",
    "        )\n",
    "        \n",
    "        self.flatten_size = 512 * 8 * 4\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, return_embedding=False):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        embedding = self.embedding(x)\n",
    "        \n",
    "        if return_embedding:\n",
    "            return embedding\n",
    "            \n",
    "        return self.classifier(embedding)\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Check for GPU availability including 4090\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            if \"4090\" in gpu_name:\n",
    "                print(f\"Found NVIDIA RTX 4090: {gpu_name}\")\n",
    "                return torch.device(f\"cuda:{i}\"), True\n",
    "        print(f\"Using available GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        return torch.device(\"cuda:0\"), True\n",
    "    elif platform.system() == \"Darwin\":  # macOS\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"Using Apple Silicon GPU\")\n",
    "            return torch.device(\"mps\"), False\n",
    "    print(\"Using CPU\")\n",
    "    return torch.device(\"cpu\"), False\n",
    "\n",
    "def train_model(train_loader, val_loader, model, device, cuda_available=False, num_epochs=100):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5)\n",
    "    \n",
    "    # Only use GradScaler when CUDA is available\n",
    "    scaler = GradScaler('cuda') if cuda_available else None\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience = 10  # Early stopping as per paper\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for specs, labels, _ in train_loader:\n",
    "            specs = specs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if cuda_available:\n",
    "                # Use mixed precision only with CUDA\n",
    "                with autocast():\n",
    "                    outputs = model(specs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Regular training for CPU/MPS\n",
    "                outputs = model(specs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for specs, labels, _ in val_loader:\n",
    "                specs = specs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                if cuda_available:\n",
    "                    with autocast():\n",
    "                        outputs = model(specs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                else:\n",
    "                    outputs = model(specs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100. * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.3f} | Train Acc: {train_acc:.3f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.3f} | Val Acc: {val_acc:.3f}%')\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "def analyze_participants(df):\n",
    "    \"\"\"Detailed analysis of participants in both datasets\"\"\"\n",
    "    # AVP participants (P1, P2, etc.)\n",
    "    avp_participants = sorted([p for p in df['participant_id'].unique() if p.startswith('P')])\n",
    "    \n",
    "    # LVT participants (handling I/P pairs)\n",
    "    lvt_ids = [p for p in df['participant_id'].unique() if not p.startswith('P')]\n",
    "    lvt_base_names = sorted(list(set([p[:-1] for p in lvt_ids if p not in ['JoSP']])))\n",
    "    \n",
    "    print(\"\\nDetailed Participant Analysis:\")\n",
    "    print(f\"AVP Dataset ({len(avp_participants)} participants):\")\n",
    "    print(avp_participants)\n",
    "    \n",
    "    print(f\"\\nLVT Dataset ({len(lvt_base_names)} participants):\")\n",
    "    for base_name in lvt_base_names:\n",
    "        has_I = f\"{base_name}I\" in lvt_ids\n",
    "        has_P = f\"{base_name}P\" in lvt_ids or (base_name == 'JSo' and 'JoSP' in lvt_ids)\n",
    "        print(f\"{base_name}: {'I' if has_I else '-'}{'P' if has_P else '-'}\")\n",
    "    \n",
    "    total_participants = len(avp_participants) + len(lvt_base_names)\n",
    "    print(f\"\\nTotal unique participants: {total_participants}\")\n",
    "    print(f\"- AVP Dataset: {len(avp_participants)} participants\")\n",
    "    print(f\"- LVT Dataset: {len(lvt_base_names)} participants\")\n",
    "    \n",
    "    return avp_participants, lvt_base_names\n",
    "\n",
    "def main():\n",
    "    # Get device and CUDA availability\n",
    "    device, cuda_available = get_device()\n",
    "    \n",
    "    # Enable CUDA optimizations only if available\n",
    "    if cuda_available:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = AudioDataset(\n",
    "        segment_info_path='../../../segment_info/segment_info.csv',\n",
    "        train=True\n",
    "    )\n",
    "    \n",
    "    # Analyze participants\n",
    "    avp_participants, lvt_base_names = analyze_participants(dataset.df)\n",
    "    \n",
    "    # Create participant groups for splitting\n",
    "    def get_participant_group(participant_id):\n",
    "        \"\"\"Convert participant ID to a group number, handling the JSo/JoS case\"\"\"\n",
    "        if participant_id.startswith('P'):\n",
    "            return int(participant_id[1:])\n",
    "        if participant_id == 'JoSP':\n",
    "            return hash('JSo')\n",
    "        return hash(participant_id[:-1])\n",
    "    \n",
    "    groups = dataset.df['participant_id'].apply(get_participant_group).values\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    n_splits = 5\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    # Storage for embeddings and labels\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    all_participants = []\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X=np.zeros(len(dataset.df)), groups=groups)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "        \n",
    "        # Determine optimal batch size and workers based on device\n",
    "        batch_size = 128 if cuda_available else 32\n",
    "        val_batch_size = 256 if cuda_available else 64\n",
    "        num_workers = 8 if cuda_available else 4\n",
    "        \n",
    "        # Optimized DataLoader settings\n",
    "        train_loader = DataLoader(\n",
    "            train_subset, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True, \n",
    "            num_workers=num_workers,\n",
    "            pin_memory=cuda_available,\n",
    "            persistent_workers=True if num_workers > 0 else False,\n",
    "            prefetch_factor=2 if num_workers > 0 else None\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_subset, \n",
    "            batch_size=val_batch_size,\n",
    "            shuffle=False, \n",
    "            num_workers=num_workers,\n",
    "            pin_memory=cuda_available,\n",
    "            persistent_workers=True if num_workers > 0 else False,\n",
    "            prefetch_factor=2 if num_workers > 0 else None\n",
    "        )\n",
    "        \n",
    "        model = DrumCNN().to(device)\n",
    "        train_model(train_loader, val_loader, model, device, cuda_available)\n",
    "        \n",
    "        # Extract embeddings\n",
    "        model.eval()\n",
    "        fold_embeddings = []\n",
    "        fold_labels = []\n",
    "        fold_participants = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for specs, labels, parts in val_loader:\n",
    "                specs = specs.to(device, non_blocking=True)\n",
    "                \n",
    "                if cuda_available:\n",
    "                    with autocast():\n",
    "                        embeddings = model(specs, return_embedding=True)\n",
    "                else:\n",
    "                    embeddings = model(specs, return_embedding=True)\n",
    "                \n",
    "                fold_embeddings.append(embeddings.cpu().numpy())\n",
    "                fold_labels.extend(labels.numpy())\n",
    "                fold_participants.extend(parts)\n",
    "        \n",
    "        all_embeddings.append(np.concatenate(fold_embeddings))\n",
    "        all_labels.extend(fold_labels)\n",
    "        all_participants.extend(fold_participants)\n",
    "    \n",
    "    # Prepare for k-NN evaluation\n",
    "    embeddings = np.concatenate(all_embeddings)\n",
    "    labels = np.array(all_labels)\n",
    "    participants = np.array(all_participants)\n",
    "    \n",
    "    print(\"\\nFinal dataset sizes:\")\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Participants shape: {participants.shape}\")\n",
    "    \n",
    "    # Scale embeddings (as per paper)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_embeddings = scaler.fit_transform(embeddings)\n",
    "    \n",
    "    # Evaluate using leave-one-participant-out\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
    "    unique_participants = np.unique(participants)\n",
    "    participant_accuracies = []\n",
    "    \n",
    "    print(\"\\nParticipant-wise evaluation:\")\n",
    "    for test_participant in unique_participants:\n",
    "        train_mask = participants != test_participant\n",
    "        test_mask = participants == test_participant\n",
    "        \n",
    "        # Scale using only training data\n",
    "        train_embeddings = scaled_embeddings[train_mask]\n",
    "        test_embeddings = scaled_embeddings[test_mask]\n",
    "        \n",
    "        knn.fit(train_embeddings, labels[train_mask])\n",
    "        accuracy = knn.score(test_embeddings, labels[test_mask])\n",
    "        participant_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"Participant {test_participant}: {accuracy:.3f}\")\n",
    "    \n",
    "    print(f\"\\nMean participant-independent accuracy: {np.mean(participant_accuracies):.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
